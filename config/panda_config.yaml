ros:
  rate: 10
  action_type: "IK" # TODO
  message_filters:
    slop: 0.1
    queue_size: 1
  additional_topics:
    - "/tf"
    - "/joint_states"
    - "/fls_camera/camera_info"
    - "/dual_panda/joint_states"
    - "/dual_panda/larm_state_controller/F_ext"
    - "/dual_panda/rarm_state_controller/F_ext"
    - "/panda_fls/target_coords"
    - "/panda_fls/eus_debug"
    - "/left_device/phantom/force_feedback"
    - "/right_device/phantom/force_feedback"
    - "/panda_fls/updater/command"
    - "/panda_fls/online_updater/command"
    - "/panda_fls/data_collector/record"
    - "/panda_fls/state_estimator/data"
    - "/panda_fls/anomaly_detector/data"
    - "/panda_fls/controller/command"

obs: # input into policy
  head_image:
    topic_name: "/fls_camera/image_rect_color/compressed"
    msg_type: "CompressedImage"
    modality: "ImageModality"
    normalize: True
    data_augmentation: True
    obs_encoder:
      model: "Resnet"
      model_path: null
      model_kwargs:
        input_size: [224, 224]
        input_channel: 3
        resnet_type: "resnet18"
        input_coord_conv: False
        pretrained: False
        latent_dim: 32
        pool: "SpatialSoftmax"
        pool_kwargs:
          num_kp: 32
          temperature: 1.0
          learnable_temperature: False
          output_variance: False
          noise_std: 0.0
      trainable: True
      input_dim: [224, 224, 3]
      activation: "ReLU"
      layer_dims: null
      output_dim: 32
      has_decoder: False
      freeze: False
  proprio:
    topic_name: "/dual_panda/joint_states"
    msg_type: "JointState"
    modality: "FloatVectorModality"
    normalize: True
    obs_encoder:
      input_dim: 8 # x0,y0,z0,x1,y1,z1,gripper0,gripper1
      output_dim: 8
      layer_dims: null
      activation: "ReLU" # [ReLU, Tanh...]
actions:
  type: "action_trajectory"
  topic_name: "/panda_fls/target_coords"
  msg_type: "Float32MultiArrayStamped"
  modality: "FloatVectorModality"
  dim: 8 # x0,y0,z0,x1,y1,z1,grasp0,grasp1
  normalize: True
task:
  language_instruction: "Pick up the blue ring and peg in the peg."

network:
  policy:
    model: "OctoActor"
    model_path: null
    transformer:
      type: "GPT"
      transformer_num_layers: 6
      transformer_num_heads: 8
      transformer_embed_dim: 512
      context_length: 20
      embed_dropout: 0.1
      attn_dropout: 0.1
      block_dropout: 0.1
      activation: "gelu"
    mlp_decoder:
      layer_dims: []
      activation: "ReLU"
      squash_output: True
    gmm:
      enabled: False
      modes: 5
      min_std: 0.0001
      low_noise_eval: True
      use_tanh: False
      std_activation: "F.softplus" # or torch.exp
    train:
      num_epochs: 1000
      batch_size: 4096
      criterion: "MSELoss"
      lr: 1e-4
      lr_scheduler: True
      supervise_all_steps: True
      optimizer: "AdamW"
      weight_decay: 0.01
      max_grad_norm: null # null or 1, 3, 5,...
      weight:
        l1: 0.0
        l2: 1.0

dataset:
  dataset_keys: ["actions"]
  load_next_obs: True
  frame_stack: 20
  pad_frame_stack: True
  pad_seq_length: True
  get_pad_mask: False
  goal_mode: null
  hdf5_cache_mode: "all"
  hdf5_use_swmr: True
